{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from conllu import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "17156477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_predicates_and_arguments_from_conllu(conllu_file):\n",
    "    sentence_dict = {}\n",
    "    predicates_and_arguments_by_sentence = []\n",
    "    \n",
    "    with open(conllu_file, 'r', encoding='utf-8') as file:\n",
    "        for sentence in file.read().strip().split('\\n\\n'):\n",
    "            sentence_predicates = []\n",
    "            sentence_arguments = []\n",
    "            sent_id = None  \n",
    "            for line in sentence.split('\\n'):\n",
    "                if line.startswith(\"# sent_id\"):\n",
    "                    sent_id = line.split(\"=\")[1].strip()  \n",
    "                    sentence_dict[sent_id] = []  \n",
    "                if line.startswith(\"#\"):\n",
    "                    continue\n",
    "                parts = line.split(\"\\t\")\n",
    "                token_id = parts[0]\n",
    "                if '.' in token_id:\n",
    "                    continue\n",
    "                if len(parts) < 11:\n",
    "                    predicate_sense = ''\n",
    "                    arguments = []\n",
    "                else:\n",
    "                    predicate_sense = parts[10]\n",
    "                    arguments = parts[11:]\n",
    "\n",
    "                if predicate_sense != '_':\n",
    "                    predicate_info = [int(token_id), predicate_sense] \n",
    "                    sentence_predicates.append(predicate_info)\n",
    "                    if sent_id:  \n",
    "                        sentence_dict[sent_id].append([predicate_info, []])  \n",
    "                        \n",
    "                for arg_token_id, arg_labels in zip(range(1, len(arguments) + 1), arguments):\n",
    "                    if arg_labels != '_':\n",
    "                        argument_info = [int(token_id), arg_labels] \n",
    "                        sentence_arguments.append(argument_info)\n",
    "                        if sent_id and sentence_dict.get(sent_id):  \n",
    "                            \n",
    "                            sentence_dict[sent_id][-1][1].append(argument_info)\n",
    "                    \n",
    "            predicates_and_arguments_by_sentence.append((sentence_predicates, sentence_arguments))\n",
    "            \n",
    "    for i, (predicates, arguments) in enumerate(predicates_and_arguments_by_sentence):\n",
    "        predicate_ids = set(token_id for token_id, _ in predicates)\n",
    "        predicates_and_arguments_by_sentence[i] = (predicates, [(token_id, label) for token_id, label in arguments if token_id not in predicate_ids])\n",
    "\n",
    "    return predicates_and_arguments_by_sentence, sentence_dict\n",
    "\n",
    "def filter_arguments(sentence_dict1):\n",
    "    for predicates in sentence_dict1.values():\n",
    "        for predicate in predicates:\n",
    "            pred_id = predicate[0][0]\n",
    "            predicate[1] = [argument for argument in predicate[1] if argument[0] != pred_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9d91d674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 'kill.01'], [[8, 'ARG1'], [18, 'ARGM-LOC']]]\n",
      "[[3, 'kill.01'], [[7, 'ARG1'], [8, 'ARGM-MOD']]]\n",
      "[[9, 'be.03'], []]\n",
      "[[10, 'cause.01'], [[11, 'ARGM-GOL'], [12, 'ARG1'], [14, 'ARGM-TMP'], [14, 'ARG1']]]\n",
      "[[16, 'come.01'], []]\n",
      "\n",
      "\n",
      "[[[3, 'kill.01'], [[7, 'ARG1'], [8, 'ARGM-MOD']]], [[9, 'be.03'], []], [[10, 'cause.01'], [[11, 'ARGM-GOL'], [12, 'ARG1'], [14, 'ARGM-TMP'], [14, 'ARG1']]], [[16, 'come.01'], []]]\n"
     ]
    }
   ],
   "source": [
    "result, sentence_dict1 = identify_predicates_and_arguments_from_conllu(\"data/en_ewt-up-train.conllu\")\n",
    "filter_arguments(sentence_dict1)\n",
    "\n",
    "print(sentence_dict1['weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0001'][0])\n",
    "print(sentence_dict1['weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0002'][0])\n",
    "print(sentence_dict1['weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0002'][1])\n",
    "print(sentence_dict1['weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0002'][2])\n",
    "print(sentence_dict1['weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0002'][3])\n",
    "print('\\n')\n",
    "print(sentence_dict1['weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0002'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17795de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e9c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0fce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
